{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from likeness import check_smiles_validity\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from ddi import process_drugbank_to_dataframe, extract_smiles_from_drugbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = ['#006B3C', '#D3AF36', '#CD9B06', '#682861', '#4A265A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../data/drugbank/drugbank.xml'\n",
    "ddi = process_drugbank_to_dataframe(file_path)\n",
    "ddi = ddi.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../data/drugbank/drugbank.xml'\n",
    "db_smiles = extract_smiles_from_drugbank(file_path)\n",
    "db_smiles = db_smiles.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi.to_csv('../../data/ddi.csv')\n",
    "db_smiles.to_csv('../../data/db_smiles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BioBert for Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi = pd.read_csv('../../data/ddi.csv')\n",
    "ddi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "embeddings = get_biobert_embeddings(ddi, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3 \n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "labels = kmeans.fit_predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_types = {0: \"major\", 1: \"moderate\", 2: \"minor\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi['labels'] = labels\n",
    "ddi['label_meaning'] = [interaction_types[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi.to_csv('../../data/ddi_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from likeness import check_smiles_validity\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi = pd.read_csv('../../data/ddi_labels.csv')\n",
    "ddi.drop(columns=['Unnamed: 0', 'primary_description'], inplace=True, errors='ignore')\n",
    "ddi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = ddi['label_meaning'].value_counts().reset_index()\n",
    "label_counts.columns = ['Label', 'Frequency']\n",
    "\n",
    "order = ['minor', 'moderate', 'major']\n",
    "color_mapping = {'minor': '#006B3C', 'moderate': '#D3AF36', 'major': '#682861'}\n",
    "label_counts['Label'] = pd.Categorical(label_counts['Label'], categories=order, ordered=True)\n",
    "label_counts = label_counts.sort_values(by='Label')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=label_counts['Label'],\n",
    "        y=label_counts['Frequency'],\n",
    "        marker=dict(color=[color_mapping[label] for label in label_counts['Label']]),\n",
    "        name=\"Labels\",\n",
    "    )\n",
    ")\n",
    "fig.update_traces(marker_line_width=1.5)\n",
    "fig.update_layout(\n",
    "    title='Label Counts',\n",
    "    xaxis_title='Label',\n",
    "    yaxis_title='Frequency',\n",
    "    template='plotly_white',\n",
    "    legend=dict(title='Labels'),\n",
    "    xaxis=dict(tickangle=45),\n",
    "    transition=dict(duration=500)\n",
    ")\n",
    "fig.write_html(\"plots/label_bar_chart.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped = ddi.groupby('label_meaning')['interaction_description'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "def color_func(*args, **kwargs):\n",
    "    return color_palette[np.random.randint(0, len(color_palette))]\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for _, row in grouped.iterrows():\n",
    "    label = row['label_meaning']\n",
    "    text = row['interaction_description']\n",
    "    wordcloud = WordCloud(\n",
    "        width=1600,\n",
    "        height=800,\n",
    "        background_color='white',\n",
    "        color_func=color_func\n",
    "    ).generate(text)\n",
    "    image_data = wordcloud.to_array()\n",
    "    fig.add_trace(\n",
    "        go.Image(z=image_data, name=label, visible=(label == 'minor'), hoverinfo='skip') \n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"dropdown\",\n",
    "            showactive=True,\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"minor\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": [label == \"minor\" for label in grouped['label_meaning']]},\n",
    "                          {\"title\": {\"text\": \"Word Cloud for Label: Minor\", \"x\": 0.5}}],\n",
    "                ),\n",
    "                dict(\n",
    "                    label=\"moderate\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": [label == \"moderate\" for label in grouped['label_meaning']]},\n",
    "                          {\"title\": {\"text\": \"Word Cloud for Label: Moderate\", \"x\": 0.5}}],\n",
    "                ),\n",
    "                dict(\n",
    "                    label=\"major\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": [label == \"major\" for label in grouped['label_meaning']]},\n",
    "                          {\"title\": {\"text\": \"Word Cloud for Label: Major\", \"x\": 0.5}}],\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\"text\": \"Word Cloud for Label: Minor\", \"x\": 0.5},\n",
    "    xaxis=dict(visible=False),\n",
    "    yaxis=dict(visible=False),\n",
    "    template='plotly_white',\n",
    "    margin=dict(l=20, r=20, t=40, b=20)\n",
    ")\n",
    "\n",
    "fig.write_html(\"plots/wordcloud_dropdown.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated pairs\n",
    "print(f'Shape before removing duplicates: {ddi.shape}')\n",
    "ddi[['primary_id', 'interacting_drug_id']] = ddi.apply(lambda x: sorted([x['primary_id'], x['interacting_drug_id']]), axis=1, result_type='expand')\n",
    "ddi.drop_duplicates(subset=['primary_id', 'interacting_drug_id'], inplace=True)\n",
    "print(f'Shape after removing duplicates: {ddi.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_smiles = pd.read_csv('../../data/db_smiles.csv')\n",
    "db_smiles.drop(columns=['Unnamed: 0', 'index'], inplace=True, errors='ignore')\n",
    "db_smiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_smiles.rename(columns={'DrugBank ID': 'primary_id', 'SMILES': 'primary_smiles'}, inplace=True)\n",
    "ddi = pd.merge(ddi, db_smiles, how='left', on='primary_id')\n",
    "db_smiles.rename(columns={'primary_id': 'interacting_drug_id', 'primary_smiles': 'interaction_drug_smiles'}, inplace=True)\n",
    "ddi = pd.merge(ddi, db_smiles, how='left', on='interacting_drug_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_isvalid = check_smiles_validity(ddi['primary_smiles'].unique())\n",
    "interaction_drug_isvalid = check_smiles_validity(ddi['interaction_drug_smiles'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_isvalid[primary_isvalid['Valid'] != True].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_drug_isvalid[interaction_drug_isvalid['Valid'] != True].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_isvalid.rename(columns={'SMILES': 'primary_smiles', 'Valid': 'primary_isvalid'}, inplace=True)\n",
    "interaction_drug_isvalid.rename(columns={'SMILES': 'interaction_drug_smiles', 'Valid': 'interaction_drug_isvalid'}, inplace=True)\n",
    "ddi = pd.merge(ddi, primary_isvalid, how='left', on='primary_smiles')\n",
    "ddi = pd.merge(ddi, interaction_drug_isvalid, how='left', on='interaction_drug_smiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi[(ddi['primary_isvalid'] != True) | (ddi['interaction_drug_isvalid'] != True)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi = ddi[(ddi['primary_isvalid'] == True) & (ddi['interaction_drug_isvalid'] == True)]\n",
    "print(f'Final shape: {ddi.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi.to_csv('../../data/ddi_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Draw, AllChem\n",
    "from rdkit import Chem\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchview import draw_graph\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib.colors import ListedColormap\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi = pd.read_csv('../../data/ddi_processed.csv')\n",
    "ddi.drop(columns=['Unnamed: 0','primary_isvalid', 'interaction_drug_isvalid'], inplace=True, errors='ignore')\n",
    "ddi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smile = ddi.iloc[0]['primary_smiles']\n",
    "m = Chem.MolFromSmiles(smile)\n",
    "img = Draw.MolToImage(m, size=(1000, 1000))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fingerprints(smiles_list, prefix):\n",
    "    molecules = [Chem.MolFromSmiles(smile) for smile in smiles_list]\n",
    "    fingerprints = [AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024) for mol in molecules]\n",
    "    fingerprint_arrays = [np.array(fingerprint) for fingerprint in fingerprints]\n",
    "    res_df = pd.DataFrame({\n",
    "        f'{prefix}_smiles': smiles_list,\n",
    "        f'{prefix}_fingerprint': fingerprint_arrays\n",
    "    })\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_fingerprint_df = create_fingerprints(ddi['primary_smiles'].unique(), 'primary')\n",
    "interaction_drug_fingerprint_df = create_fingerprints(ddi['interaction_drug_smiles'].unique(), 'interaction_drug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smile = ddi.iloc[0]['primary_smiles']\n",
    "mol = Chem.MolFromSmiles(smile)\n",
    "bi1 = {}\n",
    "fp1 = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024, bitInfo=bi1)\n",
    "print(len(list(fp1.GetOnBits())))\n",
    "tpls1 = [(mol, x, bi1) for x in fp1.GetOnBits()]\n",
    "Draw.DrawMorganBits(tpls1[:], molsPerRow=8, legends=[str(x) for x in fp1.GetOnBits()][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi = pd.merge(ddi, primary_fingerprint_df, how='left', on='primary_smiles')\n",
    "ddi = pd.merge(ddi, interaction_drug_fingerprint_df, how='left', on='interaction_drug_smiles')\n",
    "\n",
    "ddi['concat_fingerprints'] = ddi.apply(\n",
    "    lambda row: np.concatenate([row['primary_fingerprint'], row['interaction_drug_fingerprint']]), axis=1\n",
    ")\n",
    "ddi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi['len_fingerprints'] = ddi['concat_fingerprints'].apply(\n",
    "    lambda x: len(x)\n",
    ")\n",
    "print(f'Length of combined fingerprints: {ddi[\"len_fingerprints\"].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.memmap('features.dat', dtype='float16', mode='w+', shape=(len(ddi), 2048))\n",
    "labels = np.memmap('labels.dat', dtype='float16', mode='w+', shape=(len(ddi),))\n",
    "\n",
    "for i, row in enumerate(ddi['concat_fingerprints']):\n",
    "    features[i] = row\n",
    "labels[:] = ddi['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test_final, y_val, y_test_final = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "X_test_final_tensor = torch.tensor(X_test_final, dtype=torch.float32)\n",
    "y_test_final_tensor = torch.tensor(y_test_final, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_final_tensor, y_test_final_tensor)\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDI_NN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(DDI_NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 256\n",
    "output_dim = 3\n",
    "\n",
    "dummy_model = DDI_NN(input_dim, hidden_dim, output_dim)\n",
    "dummy_input = torch.randn(1, 2048)\n",
    "\n",
    "model_graph = draw_graph(\n",
    "    dummy_model,\n",
    "    input_data=(dummy_input),\n",
    "    expand_nested=True,\n",
    "    save_graph=True,\n",
    "    filename=\"drug_interaction_model_basic\", \n",
    "    directory=\"./\",\n",
    ")\n",
    "\n",
    "image = Image.open(\"drug_interaction_model_basic.png\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 256\n",
    "output_dim = 3\n",
    "model = DDI_NN(input_dim, hidden_dim, output_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "early_stop_threshold = 0.01 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for batch_idx, (batch_X, batch_y) in enumerate(train_loader):\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): \n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Val Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    if epoch > 0 and abs(val_accuracies[-1] - val_accuracies[-2]) < early_stop_threshold:\n",
    "        print(f\"Validation accuracy converged (Δ < {early_stop_threshold}%). Stopping early at epoch {epoch+1}.\")\n",
    "        break\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Train Loss', color='tab:red')\n",
    "ax1.plot(range(1, min(epoch + 2, num_epochs + 1)), train_losses, marker='o', linestyle='-', color='tab:red', label='Train Loss')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Accuracy (%)', color='tab:blue')\n",
    "ax2.plot(range(1, min(epoch + 2, num_epochs + 1)), val_accuracies, marker='s', linestyle='--', color='tab:blue', label='Val Accuracy')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Train Loss and Validation Accuracy', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        total_test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print(f\"Validation Loss: {total_test_loss / len(test_loader):.4f}\")\n",
    "print(f\"Validation Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"drug_interaction_model_basic.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_primary = np.memmap('features_primary.dat', dtype='float16', mode='w+', shape=(len(ddi), 1024))\n",
    "features_interaction = np.memmap('features_interaction.dat', dtype='float16', mode='w+', shape=(len(ddi), 1024))\n",
    "labels = np.memmap('labels.dat', dtype='float16', mode='w+', shape=(len(ddi),))\n",
    "\n",
    "for i, (fp1, fp2) in enumerate(zip(ddi['primary_fingerprint'], ddi['interaction_drug_fingerprint'])):\n",
    "    features_primary[i] = fp1\n",
    "    features_interaction[i] = fp2\n",
    "labels[:] = ddi['labels']\n",
    "\n",
    "X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(\n",
    "    features_primary, features_interaction, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "X1_val, X1_test_final, X2_val, X2_test_final, y_val, y_test_final = train_test_split(\n",
    "    X1_test, X2_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train_tensor = torch.tensor(X1_train, dtype=torch.float32)\n",
    "X2_train_tensor = torch.tensor(X2_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X1_val_tensor = torch.tensor(X1_val, dtype=torch.float32)\n",
    "X2_val_tensor = torch.tensor(X2_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X1_test_final_tensor = torch.tensor(X1_test_final, dtype=torch.float32)\n",
    "X2_test_final_tensor = torch.tensor(X2_test_final, dtype=torch.float32)\n",
    "y_test_final_tensor = torch.tensor(y_test_final, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X1_train_tensor, X2_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X1_val_tensor, X2_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X1_test_final_tensor, X2_test_final_tensor, y_test_final_tensor)\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugInteractionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DrugInteractionModel, self).__init__()\n",
    "        \n",
    "        # Encoder of each fingerprint\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Merging Layer + Classifier\n",
    "        self.fc_merge = nn.Sequential(\n",
    "            nn.Linear(256 * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, drug1, drug2):\n",
    "        encoded_drug1 = self.encoder(drug1)\n",
    "        encoded_drug2 = self.encoder(drug2)\n",
    "        merged = torch.cat((encoded_drug1, encoded_drug2), dim=1)\n",
    "        out = self.fc_merge(merged)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DrugInteractionModel()\n",
    "dummy_input_1 = torch.randn(1, 1024)\n",
    "dummy_input_2 = torch.randn(1, 1024)\n",
    "\n",
    "model_graph = draw_graph(\n",
    "    dummy_model,\n",
    "    input_data=(dummy_input_1, dummy_input_2),\n",
    "    expand_nested=True,\n",
    "    save_graph=True,\n",
    "    filename=\"drug_interaction_model\", \n",
    "    directory=\"./\",\n",
    ")\n",
    "\n",
    "image = Image.open(\"drug_interaction_model.png\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DrugInteractionModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "early_stop_threshold = 0.005 \n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X1, batch_X2, batch_y in train_loader:\n",
    "        batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X1, batch_X2)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X1, batch_X2, batch_y in val_loader:\n",
    "            batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X1, batch_X2)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(epoch_accuracy)\n",
    "\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {epoch_loss:.4f}, \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "          f\"Val Accuracy: {epoch_accuracy:.2f}%\")\n",
    "    \n",
    "    if epoch > 0 and abs(train_losses[-1] - train_losses[-2]) < early_stop_threshold:\n",
    "        print(f\"Training Loss converged (Δ < {early_stop_threshold}). Stopping early at epoch {epoch+1}.\")\n",
    "        break\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Train Loss', color='tab:red')\n",
    "ax1.plot(range(1, min(epoch + 2, num_epochs + 1)), train_losses, marker='o', linestyle='-', color='tab:red', label='Train Loss')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Accuracy (%)', color='tab:blue')\n",
    "ax2.plot(range(1, min(epoch + 2, num_epochs + 1)), val_accuracies, marker='s', linestyle='--', color='tab:blue', label='Val Accuracy')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Train Loss and Validation Accuracy', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X1, batch_X2, batch_y in test_loader:\n",
    "        batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X1, batch_X2)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss / len(test_loader):.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = ['#CD9B06', '#682861']\n",
    "cm = confusion_matrix(all_labels, all_predictions, labels=[0, 1, 2])\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "labels = [\"Minor\", \"Moderate\", \"Major\"]\n",
    "\n",
    "# Create heatmap using Plotly\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    z=cm_normalized,\n",
    "    x=labels,\n",
    "    y=labels,\n",
    "    colorscale=color_palette[:len(labels)],\n",
    "    annotation_text=np.round(cm_normalized, 2),\n",
    "    showscale=True\n",
    ")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title=\"Confusion Matrix\",\n",
    "    xaxis_title=\"Predicted Label\",\n",
    "    yaxis_title=\"True Label\",\n",
    "    yaxis=dict(autorange=\"reversed\"),\n",
    "    template=\"plotly\",\n",
    "    width=600, \n",
    "    height=600  \n",
    ")\n",
    "\n",
    "fig.write_html(\"plots/nn_cm.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"drug_interaction_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Locations Into The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_location = pd.read_csv('../../data/ddi_locations.csv')\n",
    "bd_location.drop(columns='Unnamed: 0', inplace=True)\n",
    "bd_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_location.rename(\n",
    "    columns={\n",
    "        'DrugBank ID of Ligand': 'primary_id', \n",
    "        'Latitude': 'primary_latitude', \n",
    "        'Longitude': 'primary_longitude', \n",
    "        'Institution': 'primary_institution'}, \n",
    "    inplace=True\n",
    ")\n",
    "ddi = pd.merge(ddi, bd_location, how='left', on='primary_id')\n",
    "\n",
    "bd_location.rename(\n",
    "    columns={\n",
    "        'primary_id': 'interacting_drug_id', \n",
    "        'primary_latitude': 'interacting_drug_latitude', \n",
    "        'primary_longitude': 'interacting_drug_longitude', \n",
    "        'primary_institution': 'interacting_drug_institution'}, \n",
    "    inplace=True\n",
    ")\n",
    "ddi = pd.merge(ddi, bd_location, how='left', on='interacting_drug_id')\n",
    "ddi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ddi[['primary_name', 'interacting_drug_name', 'label_meaning', 'primary_latitude', 'primary_longitude', 'interacting_drug_latitude', 'interacting_drug_longitude']]\n",
    "df.to_csv('../../data/ddi_locations_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = ddi['label_meaning'].value_counts()\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(label_counts.index, label_counts, color='#aad7d4')\n",
    "plt.title('Label Counts', fontsize=16)\n",
    "plt.xlabel('Label', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 1024 + 2\n",
    "features_primary = np.memmap('features_primary.dat', dtype='float16', mode='w+', shape=(len(ddi), num_features))\n",
    "features_interaction = np.memmap('features_interaction.dat', dtype='float16', mode='w+', shape=(len(ddi), num_features))\n",
    "labels = np.memmap('labels.dat', dtype='float16', mode='w+', shape=(len(ddi),))\n",
    "\n",
    "for i, (fp1, fp2, lat1, lon1, lat2, lon2) in enumerate(zip(\n",
    "    ddi['primary_fingerprint'], \n",
    "    ddi['interaction_drug_fingerprint'], \n",
    "    ddi['primary_latitude'], \n",
    "    ddi['primary_longitude'],\n",
    "    ddi['interacting_drug_latitude'], \n",
    "    ddi['interacting_drug_longitude']\n",
    ")):\n",
    "    features_primary[i] = np.concatenate([fp1, [lat1, lon1]])\n",
    "    features_interaction[i] = np.concatenate([fp2, [lat2, lon2]])\n",
    "labels[:] = ddi['labels']\n",
    "\n",
    "X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(\n",
    "    features_primary, features_interaction, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X1_val, X1_test_final, X2_val, X2_test_final, y_val, y_test_final = train_test_split(\n",
    "    X1_test, X2_test, y_test, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train_tensor = torch.tensor(X1_train, dtype=torch.float32)\n",
    "X2_train_tensor = torch.tensor(X2_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X1_val_tensor = torch.tensor(X1_val, dtype=torch.float32)\n",
    "X2_val_tensor = torch.tensor(X2_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X1_test_final_tensor = torch.tensor(X1_test_final, dtype=torch.float32)\n",
    "X2_test_final_tensor = torch.tensor(X2_test_final, dtype=torch.float32)\n",
    "y_test_final_tensor = torch.tensor(y_test_final, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X1_train_tensor, X2_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X1_val_tensor, X2_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X1_test_final_tensor, X2_test_final_tensor, y_test_final_tensor)\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDI_LocationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DDI_LocationModel, self).__init__()\n",
    "        \n",
    "        # Encoder for each fingerprint (1024 features only)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Merging Layer + Classifier\n",
    "        self.fc_merge = nn.Sequential(\n",
    "            nn.Linear(256 * 2 + 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, drug1, drug2):\n",
    "        fingerprint1, additional_features1 = drug1[:, :-2], drug1[:, -2:]\n",
    "        fingerprint2, additional_features2 = drug2[:, :-2], drug2[:, -2:]\n",
    "\n",
    "        encoded_drug1 = self.encoder(fingerprint1)\n",
    "        encoded_drug2 = self.encoder(fingerprint2)\n",
    "        \n",
    "        merged = torch.cat(\n",
    "            (encoded_drug1, encoded_drug2, additional_features1, additional_features2), \n",
    "            dim=1\n",
    "        )\n",
    "\n",
    "        out = self.fc_merge(merged)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DDI_LocationModel()\n",
    "dummy_input_1 = torch.randn(1, 1026)\n",
    "dummy_input_2 = torch.randn(1, 1026)\n",
    "\n",
    "model_graph = draw_graph(\n",
    "    dummy_model,\n",
    "    input_data=(dummy_input_1, dummy_input_2),\n",
    "    expand_nested=True,\n",
    "    save_graph=True,\n",
    "    filename=\"drug_interaction_locations_model\", \n",
    "    directory=\"./\",\n",
    ")\n",
    "image = Image.open(\"drug_interaction_locations_model.png\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DDI_LocationModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "early_stop_threshold = 0.01 \n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X1, batch_X2, batch_y in train_loader:\n",
    "        batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X1, batch_X2)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X1, batch_X2, batch_y in val_loader:\n",
    "            batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X1, batch_X2)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(epoch_accuracy)\n",
    "\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {epoch_loss:.4f}, \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "          f\"Val Accuracy: {epoch_accuracy:.2f}%\")\n",
    "    \n",
    "    if epoch > 0 and abs(val_accuracies[-1] - val_accuracies[-2]) < early_stop_threshold:\n",
    "        print(f\"Validation accuracy converged (Δ < {early_stop_threshold}%). Stopping early at epoch {epoch+1}.\")\n",
    "        break\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Train Loss', color='tab:red')\n",
    "ax1.plot(range(1, min(epoch + 2, num_epochs + 1)), train_losses, marker='o', linestyle='-', color='tab:red', label='Train Loss')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Accuracy (%)', color='tab:blue')\n",
    "ax2.plot(range(1, min(epoch + 2, num_epochs + 1)), val_accuracies, marker='s', linestyle='--', color='tab:blue', label='Val Accuracy')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Train Loss and Validation Accuracy', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X1, batch_X2, batch_y in test_loader:\n",
    "        batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X1, batch_X2)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss / len(test_loader):.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Data with 'no-interaction' DDI Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_non_existent_pairs(df, num_pairs):\n",
    "    primary_names = df['primary_name'].unique()\n",
    "    interacting_drugs = df['interacting_drug_name'].unique()\n",
    "\n",
    "    all_possible_pairs = set(product(primary_names, interacting_drugs))\n",
    "    existing_pairs = set(zip(df['primary_name'], df['interacting_drug_name']))\n",
    "    non_existent_pairs = all_possible_pairs - existing_pairs\n",
    "    non_existent_pairs = list(non_existent_pairs)\n",
    "\n",
    "    if len(non_existent_pairs) < num_pairs:\n",
    "        raise ValueError(\"Not enough non-existent pairs available to satisfy the requested number.\")\n",
    "\n",
    "    selected_pairs = np.random.choice(len(non_existent_pairs), size=num_pairs, replace=False)\n",
    "    selected_pairs = [non_existent_pairs[i] for i in selected_pairs]\n",
    "\n",
    "    return selected_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pairs = ddi['labels'].value_counts().max()\n",
    "new_pairs = create_random_non_existent_pairs(ddi, num_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_interaction = pd.DataFrame(new_pairs, columns=['primary_name', 'interacting_drug_name'])\n",
    "\n",
    "no_interaction['labels'] = 3\n",
    "no_interaction['label_meaning'] = 'no-interaction'\n",
    "\n",
    "ddi = pd.concat([ddi, no_interaction], ignore_index=True)\n",
    "ddi.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_columns = ddi.groupby('primary_name')[['primary_id', 'primary_smiles', 'primary_fingerprint']].apply(\n",
    "    lambda group: group.ffill().bfill()\n",
    ").reset_index()\n",
    "primary_columns.drop('level_1', inplace=True, errors='ignore')\n",
    "ddi.update(primary_columns)\n",
    "\n",
    "interaction_drug_columns = ddi.groupby('interacting_drug_name')[['interacting_drug_id', 'interaction_drug_smiles', 'interaction_drug_fingerprint']].apply(\n",
    "    lambda group: group.ffill().bfill()\n",
    ").reset_index()\n",
    "interaction_drug_columns.drop('level_1', inplace=True, errors='ignore')\n",
    "ddi.update(interaction_drug_columns)\n",
    "\n",
    "ddi.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = ddi['label_meaning'].value_counts()\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(label_counts.index, label_counts, color='#aad7d4')\n",
    "plt.title('Label Counts', fontsize=16)\n",
    "plt.xlabel('Label', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi.to_csv('../../data/ddi_augmented.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with 4 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_primary = np.memmap('features_primary.dat', dtype='float16', mode='w+', shape=(len(ddi), 1024))\n",
    "features_interaction = np.memmap('features_interaction.dat', dtype='float16', mode='w+', shape=(len(ddi), 1024))\n",
    "labels = np.memmap('labels.dat', dtype='float16', mode='w+', shape=(len(ddi),))\n",
    "\n",
    "for i, (fp1, fp2) in enumerate(zip(ddi['primary_fingerprint'], ddi['interaction_drug_fingerprint'])):\n",
    "    features_primary[i] = fp1\n",
    "    features_interaction[i] = fp2\n",
    "labels[:] = ddi['labels']\n",
    "\n",
    "X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(\n",
    "    features_primary, features_interaction, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "X1_val, X1_test_final, X2_val, X2_test_final, y_val, y_test_final = train_test_split(\n",
    "    X1_test, X2_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train_tensor = torch.tensor(X1_train, dtype=torch.float32)\n",
    "X2_train_tensor = torch.tensor(X2_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X1_val_tensor = torch.tensor(X1_val, dtype=torch.float32)\n",
    "X2_val_tensor = torch.tensor(X2_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X1_test_final_tensor = torch.tensor(X1_test_final, dtype=torch.float32)\n",
    "X2_test_final_tensor = torch.tensor(X2_test_final, dtype=torch.float32)\n",
    "y_test_final_tensor = torch.tensor(y_test_final, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X1_train_tensor, X2_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X1_val_tensor, X2_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X1_test_final_tensor, X2_test_final_tensor, y_test_final_tensor)\n",
    "\n",
    "batch_size = 4096\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugInteractionModel_4outputs(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DrugInteractionModel_4outputs, self).__init__()\n",
    "        \n",
    "        # Encoder of each fingerprint\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Merging Layer + Classifier\n",
    "        self.fc_merge = nn.Sequential(\n",
    "            nn.Linear(256 * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, drug1, drug2):\n",
    "        encoded_drug1 = self.encoder(drug1)\n",
    "        encoded_drug2 = self.encoder(drug2)\n",
    "        merged = torch.cat((encoded_drug1, encoded_drug2), dim=1)\n",
    "        out = self.fc_merge(merged)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DrugInteractionModel_4outputs().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "early_stop_threshold = 0.01 \n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X1, batch_X2, batch_y in train_loader:\n",
    "        batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X1, batch_X2)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X1, batch_X2, batch_y in val_loader:\n",
    "            batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X1, batch_X2)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(epoch_accuracy)\n",
    "\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {epoch_loss:.4f}, \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "          f\"Val Accuracy: {epoch_accuracy:.2f}%\")\n",
    "    \n",
    "    if epoch > 0 and abs(val_accuracies[-1] - val_accuracies[-2]) < early_stop_threshold:\n",
    "        print(f\"Validation accuracy converged (Δ < {early_stop_threshold}%). Stopping early at epoch {epoch+1}.\")\n",
    "        break\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Train Loss', color='tab:red')\n",
    "ax1.plot(range(1, min(epoch + 2, num_epochs + 1)), train_losses, marker='o', linestyle='-', color='tab:red', label='Train Loss')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Accuracy (%)', color='tab:blue')\n",
    "ax2.plot(range(1, min(epoch + 2, num_epochs + 1)), val_accuracies, marker='s', linestyle='--', color='tab:blue', label='Val Accuracy')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Train Loss and Validation Accuracy', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with loaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DrugInteractionModel()\n",
    "model.load_state_dict(torch.load(\"drug_interaction_model.pth\"))\n",
    "model.eval() \n",
    "print(\"Model loaded successfully from 'drug_interaction_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X1, batch_X2, batch_y in test_loader:\n",
    "        batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X1, batch_X2)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss / len(test_loader):.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = ['#CD9B06', '#682861']\n",
    "cm = confusion_matrix(all_labels, all_predictions, labels=[0, 1, 2])\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "labels = [\"Minor\", \"Moderate\", \"Major\"]\n",
    "\n",
    "# Create heatmap using Plotly\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    z=cm_normalized,\n",
    "    x=labels,\n",
    "    y=labels,\n",
    "    colorscale=color_palette[:len(labels)],\n",
    "    annotation_text=np.round(cm_normalized, 2),\n",
    "    showscale=True\n",
    ")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title=\"Confusion Matrix\",\n",
    "    xaxis_title=\"Predicted Label\",\n",
    "    yaxis_title=\"True Label\",\n",
    "    yaxis=dict(autorange=\"reversed\"),\n",
    "    template=\"plotly\",\n",
    "    width=600, \n",
    "    height=600  \n",
    ")\n",
    "\n",
    "fig.write_html(\"plots/nn_cm.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likeness and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse DDI for Most Likable Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecular Weight</th>\n",
       "      <th>Log P</th>\n",
       "      <th>H Donors</th>\n",
       "      <th>H Acceptors</th>\n",
       "      <th>Rotatable Bonds</th>\n",
       "      <th>PSA</th>\n",
       "      <th>QED Score</th>\n",
       "      <th>Lipinski Pass</th>\n",
       "      <th>Veber Pass</th>\n",
       "      <th>DrugBank ID of Ligand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>281.380</td>\n",
       "      <td>3.39872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.31</td>\n",
       "      <td>0.798242</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>DB07472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266.304</td>\n",
       "      <td>2.65122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.12</td>\n",
       "      <td>0.861716</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>DB00238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>266.304</td>\n",
       "      <td>2.65122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.12</td>\n",
       "      <td>0.861716</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>DB00238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266.304</td>\n",
       "      <td>2.65122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.12</td>\n",
       "      <td>0.861716</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>DB00238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>266.304</td>\n",
       "      <td>2.65122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.12</td>\n",
       "      <td>0.861716</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>DB00238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Molecular Weight    Log P  H Donors  H Acceptors  Rotatable Bonds    PSA  \\\n",
       "0           281.380  3.39872       0.0          2.0              1.0  20.31   \n",
       "1           266.304  2.65122       1.0          4.0              1.0  58.12   \n",
       "2           266.304  2.65122       1.0          4.0              1.0  58.12   \n",
       "3           266.304  2.65122       1.0          4.0              1.0  58.12   \n",
       "4           266.304  2.65122       1.0          4.0              1.0  58.12   \n",
       "\n",
       "   QED Score  Lipinski Pass  Veber Pass DrugBank ID of Ligand  \n",
       "0   0.798242           True        True               DB07472  \n",
       "1   0.861716           True        True               DB00238  \n",
       "2   0.861716           True        True               DB00238  \n",
       "3   0.861716           True        True               DB00238  \n",
       "4   0.861716           True        True               DB00238  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_like_df = pd.read_csv('../../data/most_likable_drugs_withDB.csv')\n",
    "most_like_df.drop(columns=['Unnamed: 0', 'BindingDB Reactant_set_id', 'Ligand SMILES', 'BindingDB Ligand Name', 'Target Name', 'Color'], inplace=True)\n",
    "most_like_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi = pd.read_csv('../../data/ddi_processed.csv')\n",
    "ddi.drop(columns=['Unnamed: 0','primary_isvalid', 'interaction_drug_isvalid'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi_most_liked = ddi[(ddi['primary_id'].isin(most_like_df['DrugBank ID of Ligand'])) | \n",
    "                     (ddi['interacting_drug_id'].isin(most_like_df['DrugBank ID of Ligand']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1163415, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17341, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddi_most_liked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = ddi_most_liked['label_meaning'].value_counts().reset_index()\n",
    "label_counts.columns = ['Label', 'Frequency']\n",
    "ddi_label_counts = ddi['label_meaning'].value_counts().reset_index()\n",
    "ddi_label_counts.columns = ['Label', 'Frequency']\n",
    "\n",
    "order = ['minor', 'moderate', 'major']\n",
    "ddi_color_mapping = {'minor': '#006B3C', 'moderate': '#D3AF36', 'major': '#682861'}\n",
    "color_mapping = {'minor': '#03a960', 'moderate': '#ffd546', 'major': '#9439d9'}\n",
    "label_counts['Label'] = pd.Categorical(label_counts['Label'], categories=order, ordered=True)\n",
    "ddi_label_counts['Label'] = pd.Categorical(ddi_label_counts['Label'], categories=order, ordered=True)\n",
    "ddi_label_counts = ddi_label_counts.sort_values(by='Label')\n",
    "label_counts = label_counts.sort_values(by='Label')\n",
    "\n",
    "percentage_diff = ((ddi_label_counts['Frequency'] - label_counts['Frequency']) / ddi_label_counts['Frequency']) * 100\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=ddi_label_counts['Label'],\n",
    "        y=ddi_label_counts['Frequency'],\n",
    "        marker=dict(color=[ddi_color_mapping[label] for label in ddi_label_counts['Label']]),\n",
    "        name=f\"All DDI\",\n",
    "        showlegend=False\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=label_counts['Label'],\n",
    "        y=label_counts['Frequency'],\n",
    "        marker=dict(color=[color_mapping[label] for label in label_counts['Label']]),\n",
    "        name=f\"Likable DDI\",\n",
    "        showlegend=False\n",
    "    )\n",
    ")\n",
    "\n",
    "for i, row in label_counts.iterrows():\n",
    "    label = row['Label']\n",
    "    likable_freq = row['Frequency']\n",
    "    all_ddi_freq = ddi_label_counts[ddi_label_counts['Label'] == label]['Frequency'].values[0]\n",
    "    \n",
    "    # Calculate percentage drop\n",
    "    perc_drop = ((all_ddi_freq - likable_freq) / all_ddi_freq) * 100\n",
    "    perc_drop_text = f\"{perc_drop:.1f}% drop\"\n",
    "    \n",
    "    # Get the corresponding color for the Likable DDI bar\n",
    "    bar_color = color_mapping[label]\n",
    "    \n",
    "    # Add annotation to the plot\n",
    "    fig.add_annotation(\n",
    "        x=label,\n",
    "        y=1.2*likable_freq,  # Position the text slightly above the 'Likable DDI' bars\n",
    "        text=perc_drop_text,\n",
    "        showarrow=False,\n",
    "        font=dict(size=12, color='black'),  # Use the corresponding color for the text\n",
    "        align='center'\n",
    "    )\n",
    "# Update the plot layout\n",
    "fig.update_traces(marker_line_width=1.5)\n",
    "fig.update_layout(\n",
    "    title='Label Counts for Most Likable Drugs (vs. All Labels)',\n",
    "    xaxis_title='Label',\n",
    "    yaxis_title='Frequency',\n",
    "    template='plotly_white',\n",
    "    xaxis=dict(tickangle=45),\n",
    "    barmode='group',  # Ensure bars are grouped next to each other\n",
    "    transition=dict(duration=500)\n",
    ")\n",
    "\n",
    "fig.write_html(\"plots/label_bar_chart_with_ddi_frequencies.html\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_like_df_primary = most_like_df.rename(columns={\n",
    "    'Molecular Weight': 'primary_mol_weight',\n",
    "    'Log P': 'primary_log_p',\n",
    "    'H Donors': 'primary_h_donors',\n",
    "    'H Acceptors': 'primary_h_acceptors',\n",
    "    'Rotatable Bonds': 'primary_rotatable_bonds',\n",
    "    'PSA': 'primary_psa',\n",
    "    'QED Score': 'primary_qed_score',\n",
    "    'Lipinski Pass': 'primary_lipinski_pass',\n",
    "    'Veber Pass': 'primary_veber_pass'\n",
    "})\n",
    "most_liked_ddi_primary = pd.merge(ddi, most_like_df_primary, left_on='primary_id', right_on='DrugBank ID of Ligand', how='left')\n",
    "\n",
    "most_like_df_interacting = most_like_df.rename(columns={\n",
    "    'Molecular Weight': 'interacting_mol_weight',\n",
    "    'Log P': 'interacting_log_p',\n",
    "    'H Donors': 'interacting_h_donors',\n",
    "    'H Acceptors': 'interacting_h_acceptors',\n",
    "    'Rotatable Bonds': 'interacting_rotatable_bonds',\n",
    "    'PSA': 'interacting_psa',\n",
    "    'QED Score': 'interacting_qed_score',\n",
    "    'Lipinski Pass': 'interacting_lipinski_pass',\n",
    "    'Veber Pass': 'interacting_veber_pass'\n",
    "})\n",
    "most_liked_ddi_interacting = pd.merge(ddi, most_like_df_interacting, left_on='interacting_drug_id', right_on='DrugBank ID of Ligand', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = ddi['label_meaning'].value_counts().reset_index()\n",
    "label_counts.columns = ['Label', 'Frequency']\n",
    "\n",
    "order = ['minor', 'moderate', 'major']\n",
    "color_mapping = {'minor': '#006B3C', 'moderate': '#D3AF36', 'major': '#682861'}\n",
    "label_counts['Label'] = pd.Categorical(label_counts['Label'], categories=order, ordered=True)\n",
    "label_counts = label_counts.sort_values(by='Label')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=label_counts['Label'],\n",
    "        y=label_counts['Frequency'],\n",
    "        marker=dict(color=[color_mapping[label] for label in label_counts['Label']]),\n",
    "        name=\"Labels\",\n",
    "    )\n",
    ")\n",
    "fig.update_traces(marker_line_width=1.5)\n",
    "fig.update_layout(\n",
    "    title='Label Counts for Most Likable Drugs',\n",
    "    xaxis_title='Label',\n",
    "    yaxis_title='Frequency',\n",
    "    template='plotly_white',\n",
    "    legend=dict(title='Labels'),\n",
    "    xaxis=dict(tickangle=45),\n",
    "    transition=dict(duration=500)\n",
    ")\n",
    "fig.write_html(\"plots/label_bar_chart.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize DDI on a Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import AntPath\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/ddi_locations_preprocessed.csv')\n",
    "df.drop(columns='Unnamed: 0',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = df.sample(frac=0.01, random_state=42)\n",
    "label_colors = {\n",
    "    'major': 'red',\n",
    "    'moderate': 'yellow',\n",
    "    'minor': 'green'\n",
    "}\n",
    "map_center = [sampled_df['primary_latitude'].mean(), sampled_df['primary_longitude'].mean()]\n",
    "interaction_map = folium.Map(location=map_center, zoom_start=2, tiles='cartodbpositron')\n",
    "for _, row in sampled_df.iterrows():\n",
    "    start_point = [row['primary_latitude'], row['primary_longitude']]\n",
    "    end_point = [row['interacting_drug_latitude'], row['interacting_drug_longitude']]\n",
    "\n",
    "    line_color = label_colors.get(row['label_meaning'], 'gray') \n",
    "\n",
    "    folium.PolyLine(\n",
    "        locations=[start_point, end_point],\n",
    "        color=line_color,\n",
    "        weight=0.2, \n",
    "        opacity=0.7\n",
    "    ).add_to(interaction_map)\n",
    "\n",
    "interaction_map.save('ddi_interaction_map.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(interaction_map._repr_html_()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
